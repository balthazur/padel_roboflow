{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/CaseSensitive/Development/padel_roboflow_2/venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - auc_148: 0.1368 - loss: 0.9561\n",
      "Epoch 2/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.2523 - loss: 0.8802\n",
      "Epoch 3/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - auc_148: 0.3760 - loss: 0.6982\n",
      "Epoch 4/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.5368 - loss: 0.6147\n",
      "Epoch 5/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.4591 - loss: 0.6584\n",
      "Epoch 6/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.6086 - loss: 0.5584\n",
      "Epoch 7/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.6679 - loss: 0.4377\n",
      "Epoch 8/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.7024 - loss: 0.4615\n",
      "Epoch 9/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.6404 - loss: 0.4111\n",
      "Epoch 10/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.6121 - loss: 0.4684\n",
      "Epoch 11/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.7273 - loss: 0.3912\n",
      "Epoch 12/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.7371 - loss: 0.4616\n",
      "Epoch 13/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.7156 - loss: 0.3846\n",
      "Epoch 14/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.7625 - loss: 0.3906\n",
      "Epoch 15/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.7704 - loss: 0.3635\n",
      "Epoch 16/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.7665 - loss: 0.3808\n",
      "Epoch 17/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.7787 - loss: 0.3342\n",
      "Epoch 18/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.7643 - loss: 0.3187\n",
      "Epoch 19/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.7985 - loss: 0.3268\n",
      "Epoch 20/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.8133 - loss: 0.2982\n",
      "Epoch 21/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.8301 - loss: 0.2859\n",
      "Epoch 22/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.8049 - loss: 0.3392\n",
      "Epoch 23/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.7992 - loss: 0.2732\n",
      "Epoch 24/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.7447 - loss: 0.3529\n",
      "Epoch 25/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.7778 - loss: 0.3118\n",
      "Epoch 26/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.8427 - loss: 0.2621\n",
      "Epoch 27/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.8877 - loss: 0.2190\n",
      "Epoch 28/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.7309 - loss: 0.3126\n",
      "Epoch 29/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.8851 - loss: 0.2308\n",
      "Epoch 30/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_148: 0.8554 - loss: 0.2497\n",
      "Score for fold 1: Precision: 0.9354, Recall: 0.8715, F1 Score: 0.8920, AUC (PR): 0.7192\n",
      "Training for fold 2...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/CaseSensitive/Development/padel_roboflow_2/venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - auc_149: 0.1343 - loss: 0.9799\n",
      "Epoch 2/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.2500 - loss: 0.8788\n",
      "Epoch 3/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.4398 - loss: 0.7421\n",
      "Epoch 4/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.5434 - loss: 0.6495\n",
      "Epoch 5/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.5669 - loss: 0.5932\n",
      "Epoch 6/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.5925 - loss: 0.5615\n",
      "Epoch 7/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.6409 - loss: 0.5309\n",
      "Epoch 8/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.6424 - loss: 0.4474\n",
      "Epoch 9/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.6350 - loss: 0.5064\n",
      "Epoch 10/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.7078 - loss: 0.3914\n",
      "Epoch 11/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.6623 - loss: 0.4320\n",
      "Epoch 12/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.6969 - loss: 0.4382\n",
      "Epoch 13/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.7191 - loss: 0.3901\n",
      "Epoch 14/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.7476 - loss: 0.3604\n",
      "Epoch 15/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.5333 - loss: 0.4809\n",
      "Epoch 16/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.6935 - loss: 0.4268\n",
      "Epoch 17/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.6356 - loss: 0.4274\n",
      "Epoch 18/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.7130 - loss: 0.3580\n",
      "Epoch 19/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.7399 - loss: 0.3447\n",
      "Epoch 20/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.7139 - loss: 0.3424\n",
      "Epoch 21/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.6877 - loss: 0.3968\n",
      "Epoch 22/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.7257 - loss: 0.3484\n",
      "Epoch 23/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.8141 - loss: 0.2898\n",
      "Epoch 24/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.8012 - loss: 0.2897\n",
      "Epoch 25/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.8169 - loss: 0.3166\n",
      "Epoch 26/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.7930 - loss: 0.3024\n",
      "Epoch 27/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.6273 - loss: 0.3832\n",
      "Epoch 28/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.7622 - loss: 0.3237\n",
      "Epoch 29/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.8342 - loss: 0.2495\n",
      "Epoch 30/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_149: 0.8670 - loss: 0.2263\n",
      "Score for fold 2: Precision: 0.9447, Recall: 0.9075, F1 Score: 0.9180, AUC (PR): 0.8139\n",
      "Training for fold 3...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/CaseSensitive/Development/padel_roboflow_2/venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - auc_150: 0.1487 - loss: 0.9946\n",
      "Epoch 2/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.1877 - loss: 0.8637\n",
      "Epoch 3/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.3243 - loss: 0.7788\n",
      "Epoch 4/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.4177 - loss: 0.7301\n",
      "Epoch 5/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.4659 - loss: 0.6052\n",
      "Epoch 6/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.5877 - loss: 0.5865\n",
      "Epoch 7/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.6650 - loss: 0.5182\n",
      "Epoch 8/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.6139 - loss: 0.4726\n",
      "Epoch 9/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.6201 - loss: 0.4784\n",
      "Epoch 10/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.5906 - loss: 0.5568\n",
      "Epoch 11/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.7039 - loss: 0.3994\n",
      "Epoch 12/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.6342 - loss: 0.4422\n",
      "Epoch 13/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.7238 - loss: 0.3991\n",
      "Epoch 14/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.7204 - loss: 0.3848\n",
      "Epoch 15/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.7450 - loss: 0.3705\n",
      "Epoch 16/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.7314 - loss: 0.3790\n",
      "Epoch 17/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - auc_150: 0.7677 - loss: 0.3292\n",
      "Epoch 18/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.7421 - loss: 0.3437\n",
      "Epoch 19/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.7132 - loss: 0.3714\n",
      "Epoch 20/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.7127 - loss: 0.3447\n",
      "Epoch 21/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.7571 - loss: 0.3633\n",
      "Epoch 22/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.7477 - loss: 0.3371\n",
      "Epoch 23/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.7730 - loss: 0.2944\n",
      "Epoch 24/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.7769 - loss: 0.2823\n",
      "Epoch 25/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.8045 - loss: 0.3251\n",
      "Epoch 26/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.8294 - loss: 0.2791\n",
      "Epoch 27/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.8189 - loss: 0.2710\n",
      "Epoch 28/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.8408 - loss: 0.2553\n",
      "Epoch 29/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.8420 - loss: 0.2609\n",
      "Epoch 30/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_150: 0.8351 - loss: 0.2526\n",
      "Score for fold 3: Precision: 0.9332, Recall: 0.8946, F1 Score: 0.9059, AUC (PR): 0.8324\n",
      "Training for fold 4...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/CaseSensitive/Development/padel_roboflow_2/venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - auc_151: 0.1361 - loss: 0.9612\n",
      "Epoch 2/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.2631 - loss: 0.8846\n",
      "Epoch 3/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.3358 - loss: 0.7595\n",
      "Epoch 4/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - auc_151: 0.3791 - loss: 0.6994\n",
      "Epoch 5/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.4451 - loss: 0.6386\n",
      "Epoch 6/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.5278 - loss: 0.6263\n",
      "Epoch 7/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.5383 - loss: 0.5371\n",
      "Epoch 8/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.6361 - loss: 0.4912\n",
      "Epoch 9/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.6353 - loss: 0.4547\n",
      "Epoch 10/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.5838 - loss: 0.4731\n",
      "Epoch 11/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.5684 - loss: 0.4543\n",
      "Epoch 12/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.6581 - loss: 0.4453\n",
      "Epoch 13/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.6622 - loss: 0.4221\n",
      "Epoch 14/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.7390 - loss: 0.3690\n",
      "Epoch 15/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.5691 - loss: 0.4381\n",
      "Epoch 16/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.6102 - loss: 0.4350\n",
      "Epoch 17/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.7171 - loss: 0.3492\n",
      "Epoch 18/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.7624 - loss: 0.3446\n",
      "Epoch 19/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.7935 - loss: 0.3178\n",
      "Epoch 20/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.8145 - loss: 0.2919\n",
      "Epoch 21/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.7095 - loss: 0.3598\n",
      "Epoch 22/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.7826 - loss: 0.3491\n",
      "Epoch 23/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.8376 - loss: 0.2691\n",
      "Epoch 24/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.7960 - loss: 0.2784\n",
      "Epoch 25/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.8427 - loss: 0.3104\n",
      "Epoch 26/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.8221 - loss: 0.2504\n",
      "Epoch 27/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.7689 - loss: 0.3052\n",
      "Epoch 28/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.7646 - loss: 0.2906\n",
      "Epoch 29/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.8372 - loss: 0.2611\n",
      "Epoch 30/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_151: 0.8442 - loss: 0.2327\n",
      "Score for fold 4: Precision: 0.9342, Recall: 0.8766, F1 Score: 0.8957, AUC (PR): 0.6211\n",
      "Training for fold 5...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/CaseSensitive/Development/padel_roboflow_2/venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - auc_152: 0.1510 - loss: 0.9388\n",
      "Epoch 2/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.2272 - loss: 0.8582\n",
      "Epoch 3/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.3834 - loss: 0.7253\n",
      "Epoch 4/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.5114 - loss: 0.6182\n",
      "Epoch 5/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.5582 - loss: 0.5295\n",
      "Epoch 6/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.6640 - loss: 0.5078\n",
      "Epoch 7/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - auc_152: 0.5330 - loss: 0.5707\n",
      "Epoch 8/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.5160 - loss: 0.5548\n",
      "Epoch 9/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.6467 - loss: 0.4935\n",
      "Epoch 10/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.7472 - loss: 0.3924\n",
      "Epoch 11/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.6762 - loss: 0.4148\n",
      "Epoch 12/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.7172 - loss: 0.4324\n",
      "Epoch 13/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.7196 - loss: 0.3923\n",
      "Epoch 14/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.6574 - loss: 0.3933\n",
      "Epoch 15/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.7442 - loss: 0.3765\n",
      "Epoch 16/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.7158 - loss: 0.4116\n",
      "Epoch 17/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.7416 - loss: 0.3846\n",
      "Epoch 18/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.6638 - loss: 0.3866\n",
      "Epoch 19/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.6902 - loss: 0.4009\n",
      "Epoch 20/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.7765 - loss: 0.3683\n",
      "Epoch 21/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.8060 - loss: 0.3073\n",
      "Epoch 22/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.7863 - loss: 0.2891\n",
      "Epoch 23/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.7799 - loss: 0.3311\n",
      "Epoch 24/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.8387 - loss: 0.3055\n",
      "Epoch 25/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.8102 - loss: 0.2813\n",
      "Epoch 26/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.8162 - loss: 0.2725\n",
      "Epoch 27/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - auc_152: 0.8521 - loss: 0.2359\n",
      "Epoch 28/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.7819 - loss: 0.2764\n",
      "Epoch 29/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.8159 - loss: 0.3075\n",
      "Epoch 30/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_152: 0.8488 - loss: 0.2325\n",
      "Score for fold 5: Precision: 0.9353, Recall: 0.8278, F1 Score: 0.8625, AUC (PR): 0.4607\n",
      "Training for fold 6...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/CaseSensitive/Development/padel_roboflow_2/venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - auc_153: 0.1557 - loss: 0.9494\n",
      "Epoch 2/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.2781 - loss: 0.8888\n",
      "Epoch 3/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.3944 - loss: 0.7848\n",
      "Epoch 4/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.4851 - loss: 0.6974\n",
      "Epoch 5/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.5491 - loss: 0.6269\n",
      "Epoch 6/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.5015 - loss: 0.5950\n",
      "Epoch 7/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.6062 - loss: 0.5584\n",
      "Epoch 8/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.6692 - loss: 0.4886\n",
      "Epoch 9/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.6305 - loss: 0.4828\n",
      "Epoch 10/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - auc_153: 0.6547 - loss: 0.4419\n",
      "Epoch 11/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.6552 - loss: 0.4626\n",
      "Epoch 12/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.6776 - loss: 0.4585\n",
      "Epoch 13/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.6746 - loss: 0.4332\n",
      "Epoch 14/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.7135 - loss: 0.4227\n",
      "Epoch 15/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.7544 - loss: 0.3692\n",
      "Epoch 16/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.7671 - loss: 0.3664\n",
      "Epoch 17/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.7747 - loss: 0.3397\n",
      "Epoch 18/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.7930 - loss: 0.3317\n",
      "Epoch 19/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.7444 - loss: 0.3194\n",
      "Epoch 20/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.7491 - loss: 0.3723\n",
      "Epoch 21/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.7269 - loss: 0.3626\n",
      "Epoch 22/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.7420 - loss: 0.3172\n",
      "Epoch 23/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.7623 - loss: 0.3354\n",
      "Epoch 24/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.8107 - loss: 0.2663\n",
      "Epoch 25/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.8184 - loss: 0.2875\n",
      "Epoch 26/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.8531 - loss: 0.2476\n",
      "Epoch 27/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.7756 - loss: 0.3053\n",
      "Epoch 28/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.8537 - loss: 0.2307\n",
      "Epoch 29/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.8534 - loss: 0.2441\n",
      "Epoch 30/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_153: 0.8289 - loss: 0.2431\n",
      "Score for fold 6: Precision: 0.9193, Recall: 0.8479, F1 Score: 0.8706, AUC (PR): 0.6562\n",
      "Training for fold 7...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/CaseSensitive/Development/padel_roboflow_2/venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - auc_154: 0.1507 - loss: 0.9306\n",
      "Epoch 2/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_154: 0.2383 - loss: 0.8650\n",
      "Epoch 3/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.2985 - loss: 0.7716\n",
      "Epoch 4/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_154: 0.4450 - loss: 0.6012\n",
      "Epoch 5/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_154: 0.5357 - loss: 0.5389\n",
      "Epoch 6/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_154: 0.6012 - loss: 0.5056\n",
      "Epoch 7/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.6279 - loss: 0.5023\n",
      "Epoch 8/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.6207 - loss: 0.4672\n",
      "Epoch 9/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_154: 0.6454 - loss: 0.5033\n",
      "Epoch 10/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_154: 0.6874 - loss: 0.4021\n",
      "Epoch 11/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.6719 - loss: 0.4489\n",
      "Epoch 12/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.7234 - loss: 0.4218\n",
      "Epoch 13/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.6803 - loss: 0.4088\n",
      "Epoch 14/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.6340 - loss: 0.4044\n",
      "Epoch 15/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_154: 0.7448 - loss: 0.3866\n",
      "Epoch 16/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.6619 - loss: 0.4329\n",
      "Epoch 17/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.7823 - loss: 0.3463\n",
      "Epoch 18/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_154: 0.7630 - loss: 0.3598\n",
      "Epoch 19/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.6068 - loss: 0.4185\n",
      "Epoch 20/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_154: 0.7363 - loss: 0.3442\n",
      "Epoch 21/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_154: 0.7768 - loss: 0.3406\n",
      "Epoch 22/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.7342 - loss: 0.3310\n",
      "Epoch 23/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_154: 0.8074 - loss: 0.2836\n",
      "Epoch 24/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.8503 - loss: 0.2824\n",
      "Epoch 25/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.5425 - loss: 0.4516\n",
      "Epoch 26/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_154: 0.8224 - loss: 0.2761\n",
      "Epoch 27/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_154: 0.7905 - loss: 0.3284\n",
      "Epoch 28/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.8339 - loss: 0.2444\n",
      "Epoch 29/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_154: 0.8491 - loss: 0.2485\n",
      "Epoch 30/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_154: 0.8198 - loss: 0.2846\n",
      "Score for fold 7: Precision: 0.9144, Recall: 0.8505, F1 Score: 0.8707, AUC (PR): 0.7208\n",
      "Training for fold 8...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/CaseSensitive/Development/padel_roboflow_2/venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - auc_155: 0.1560 - loss: 0.9579\n",
      "Epoch 2/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.2196 - loss: 0.8533\n",
      "Epoch 3/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.4130 - loss: 0.7015\n",
      "Epoch 4/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.4584 - loss: 0.6734\n",
      "Epoch 5/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.4223 - loss: 0.6564\n",
      "Epoch 6/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.4732 - loss: 0.5923\n",
      "Epoch 7/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_155: 0.5328 - loss: 0.5286\n",
      "Epoch 8/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_155: 0.6655 - loss: 0.4885\n",
      "Epoch 9/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_155: 0.5411 - loss: 0.5169\n",
      "Epoch 10/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.6302 - loss: 0.4758\n",
      "Epoch 11/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.6323 - loss: 0.4365\n",
      "Epoch 12/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.6854 - loss: 0.4190\n",
      "Epoch 13/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.7288 - loss: 0.3562\n",
      "Epoch 14/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_155: 0.7372 - loss: 0.3630\n",
      "Epoch 15/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.6593 - loss: 0.4087\n",
      "Epoch 16/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_155: 0.7359 - loss: 0.3413\n",
      "Epoch 17/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_155: 0.7073 - loss: 0.3633\n",
      "Epoch 18/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_155: 0.8009 - loss: 0.2975\n",
      "Epoch 19/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_155: 0.8268 - loss: 0.2722\n",
      "Epoch 20/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_155: 0.7820 - loss: 0.2998\n",
      "Epoch 21/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_155: 0.8482 - loss: 0.2658\n",
      "Epoch 22/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.7438 - loss: 0.3421\n",
      "Epoch 23/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.8156 - loss: 0.3070\n",
      "Epoch 24/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_155: 0.8351 - loss: 0.2374\n",
      "Epoch 25/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.8078 - loss: 0.2677\n",
      "Epoch 26/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.8044 - loss: 0.3085\n",
      "Epoch 27/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.7713 - loss: 0.3002\n",
      "Epoch 28/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.8313 - loss: 0.2936\n",
      "Epoch 29/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_155: 0.7979 - loss: 0.2610\n",
      "Epoch 30/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_155: 0.8496 - loss: 0.2417\n",
      "Score for fold 8: Precision: 0.9217, Recall: 0.8299, F1 Score: 0.8547, AUC (PR): 0.7467\n",
      "Training for fold 9...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/CaseSensitive/Development/padel_roboflow_2/venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - auc_156: 0.1377 - loss: 0.9516\n",
      "Epoch 2/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.2666 - loss: 0.8908\n",
      "Epoch 3/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.3111 - loss: 0.7924\n",
      "Epoch 4/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_156: 0.5354 - loss: 0.6472\n",
      "Epoch 5/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.4744 - loss: 0.6249\n",
      "Epoch 6/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.5373 - loss: 0.5544\n",
      "Epoch 7/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.6181 - loss: 0.4734\n",
      "Epoch 8/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.6245 - loss: 0.4816\n",
      "Epoch 9/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.5882 - loss: 0.4543\n",
      "Epoch 10/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.7145 - loss: 0.4445\n",
      "Epoch 11/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.7067 - loss: 0.4104\n",
      "Epoch 12/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_156: 0.6564 - loss: 0.3908\n",
      "Epoch 13/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_156: 0.7053 - loss: 0.3905\n",
      "Epoch 14/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.7028 - loss: 0.3861\n",
      "Epoch 15/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_156: 0.7294 - loss: 0.3792\n",
      "Epoch 16/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.7453 - loss: 0.3669\n",
      "Epoch 17/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.7055 - loss: 0.3599\n",
      "Epoch 18/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_156: 0.7232 - loss: 0.3835\n",
      "Epoch 19/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.7544 - loss: 0.3146\n",
      "Epoch 20/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.6961 - loss: 0.3820\n",
      "Epoch 21/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.8021 - loss: 0.2817\n",
      "Epoch 22/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.7839 - loss: 0.3141\n",
      "Epoch 23/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_156: 0.6996 - loss: 0.3567\n",
      "Epoch 24/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_156: 0.8129 - loss: 0.3313\n",
      "Epoch 25/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_156: 0.8186 - loss: 0.2681\n",
      "Epoch 26/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_156: 0.7833 - loss: 0.3136\n",
      "Epoch 27/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.8010 - loss: 0.3088\n",
      "Epoch 28/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.7232 - loss: 0.3230\n",
      "Epoch 29/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.8391 - loss: 0.2539\n",
      "Epoch 30/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - auc_156: 0.7954 - loss: 0.2713\n",
      "Score for fold 9: Precision: 0.9303, Recall: 0.8737, F1 Score: 0.8908, AUC (PR): 0.7311\n",
      "Training for fold 10...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/CaseSensitive/Development/padel_roboflow_2/venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - auc_157: 0.1614 - loss: 0.9828\n",
      "Epoch 2/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.2412 - loss: 0.8837\n",
      "Epoch 3/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.4264 - loss: 0.7129\n",
      "Epoch 4/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.5397 - loss: 0.6339\n",
      "Epoch 5/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.5259 - loss: 0.5709\n",
      "Epoch 6/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.6199 - loss: 0.5138\n",
      "Epoch 7/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.6447 - loss: 0.5105\n",
      "Epoch 8/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.7025 - loss: 0.4429\n",
      "Epoch 9/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.6201 - loss: 0.4766\n",
      "Epoch 10/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.6462 - loss: 0.4485\n",
      "Epoch 11/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.5576 - loss: 0.4526\n",
      "Epoch 12/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.6722 - loss: 0.4300\n",
      "Epoch 13/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.6157 - loss: 0.4219\n",
      "Epoch 14/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.7214 - loss: 0.3600\n",
      "Epoch 15/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.6653 - loss: 0.3845\n",
      "Epoch 16/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.7350 - loss: 0.3760\n",
      "Epoch 17/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.7507 - loss: 0.3573\n",
      "Epoch 18/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.7788 - loss: 0.3250\n",
      "Epoch 19/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.7400 - loss: 0.3385\n",
      "Epoch 20/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.7661 - loss: 0.3017\n",
      "Epoch 21/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.7284 - loss: 0.3274\n",
      "Epoch 22/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.7130 - loss: 0.3310\n",
      "Epoch 23/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.7238 - loss: 0.3509\n",
      "Epoch 24/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.7961 - loss: 0.2993\n",
      "Epoch 25/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.7715 - loss: 0.3260\n",
      "Epoch 26/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.7137 - loss: 0.3983\n",
      "Epoch 27/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.8212 - loss: 0.2576\n",
      "Epoch 28/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.8673 - loss: 0.2434\n",
      "Epoch 29/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.7939 - loss: 0.2855\n",
      "Epoch 30/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc_157: 0.8333 - loss: 0.2352\n",
      "Score for fold 10: Precision: 0.9272, Recall: 0.8840, F1 Score: 0.8978, AUC (PR): 0.7548\n",
      "\n",
      "Best model was from fold 3\n",
      "Best model scores: Precision: 0.9332, Recall: 0.8946, F1 Score: 0.9059, AUC (PR): 0.8324\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved as models/padel_model_best_auc_pr_0.8324.keras\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC, F1Score\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv('padel_shots_dataset.csv')\n",
    "X = df.drop('label', axis=1).values\n",
    "y = df['label'].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))  # Reshape for LSTM\n",
    "\n",
    "# Cross-validation setup\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=57)\n",
    "fold_no = 1\n",
    "input_features = X_scaled.shape[2]\n",
    "\n",
    "best_model = None\n",
    "best_auc_pr = 0\n",
    "best_fold = 0\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(128, return_sequences=True), input_shape=(1, input_features)),\n",
    "        Bidirectional(LSTM(64, return_sequences=True)),\n",
    "        LSTM(32, return_sequences=False),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy',metrics=[AUC(curve=\"PR\")])\n",
    "    \n",
    "\n",
    "    # Calculate the class distribution\n",
    "    class_counts = np.bincount(y_train)\n",
    "    total_samples = len(y_train)\n",
    "\n",
    "    # Calculate inverse of frequency\n",
    "    inv_freq = total_samples / (len(class_counts) * class_counts)\n",
    "\n",
    "    # You can adjust this factor to control the emphasis on the minority class\n",
    "    adjustment_factor = 1.4  # Increase this to give more weight to the minority class\n",
    "\n",
    "    class_weights = inv_freq * adjustment_factor\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "        \n",
    "    # Train the model\n",
    "    print(f'Training for fold {fold_no}...')\n",
    "\n",
    "    # Then in your model.fit() call:\n",
    "    model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=1, class_weight=class_weight_dict)\n",
    "\n",
    "    \n",
    "    # Predict and calculate metrics for each fold\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(\"int32\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Calculate AUC (PR)\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "    auc_pr = auc(recall_curve, precision_curve)\n",
    "    \n",
    "    print(f'Score for fold {fold_no}: Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, AUC (PR): {auc_pr:.4f}')\n",
    "    \n",
    "    # Check if this is the best model so far\n",
    "    if auc_pr > best_auc_pr:\n",
    "        best_auc_pr = auc_pr\n",
    "        best_model = model\n",
    "        best_fold = fold_no\n",
    "        best_y_test = y_test\n",
    "        best_y_pred = y_pred\n",
    "        best_precision = precision\n",
    "        best_recall = recall\n",
    "        best_f1 = f1\n",
    "    \n",
    "    fold_no += 1\n",
    "\n",
    "# Print results of the best model\n",
    "print(f'\\nBest model was from fold {best_fold}')\n",
    "print(f'Best model scores: Precision: {best_precision:.4f}, Recall: {best_recall:.4f}, F1 Score: {best_f1:.4f}, AUC (PR): {best_auc_pr:.4f}')\n",
    "\n",
    "# Display confusion matrix for the best model\n",
    "cm = confusion_matrix(best_y_test, best_y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Shot', 'Shot'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(f'Confusion Matrix for Best Model (Fold {best_fold})')\n",
    "plt.show()\n",
    "\n",
    "# Save the best model\n",
    "model_filename = f'models/padel_model_best_auc_pr_{best_auc_pr:.4f}.keras'\n",
    "best_model.save(model_filename)\n",
    "print(f'Best model saved as {model_filename}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
